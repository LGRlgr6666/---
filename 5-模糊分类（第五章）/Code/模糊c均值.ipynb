{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f1a01ca-95bb-4ac1-96ee-b4dda4aebc3e",
   "metadata": {},
   "source": [
    "# 模糊c均值聚类及python实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c7cc5a-0c31-4fb9-b0d5-e1fe424c83bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "  模糊c均值聚类(Fuzzy C-Means)是引入了模糊理论的一种聚类算法，通过隶属度来表示样本属于某一类的概率，原因在于在很多情况下多个类别之间的界限并不是绝对的明确。显然，相比于k-means的硬聚类，模糊c均值聚类得到的聚类结果更灵活。\n",
    "\n",
    "  模糊c均值聚类通过最小化一下目标函数来得到聚类中心：\n",
    "\n",
    "J_{m}=∑i=1N∑j=1Cumij∥xi−cj∥2,1≤m<∞(1)\n",
    "\n",
    "其中，m>1\n",
    "为模糊系数(fuzzy coefficient)，N 为样本数，C 为聚类中心数，cj 表示第 j 个聚类中心，和样本特征维数相同，xi 表示第 i 个样本，uij 表示样本 xi 对聚类中心 cj 的隶属度(通俗的说就是 xi 属于 cj\n",
    "\n",
    "的概率)，显然满足\n",
    "\n",
    "∑j=1Cuij=1(2)\n",
    "\n",
    "||∗||\n",
    "\n",
    "可以是任意度量数据相似性(距离)的范数，最常见的就是欧几里得范数（又称欧氏范数，L2范数，欧氏距离）：\n",
    "\n",
    "d=∥x∥2=∑ix2i−−−−−√(3)\n",
    "\n",
    "  模糊c均值聚类通过更新 uij\n",
    "和 cj\n",
    "\n",
    "来迭代地优化目标函数Eq. (1)：\n",
    "\n",
    "uij=1∑Ck=1(∥xi−cj∥∥xi−ck∥)2m−1(4)\n",
    "\n",
    "cj=∑Ni=1umij⋅xi∑Ni=1umij(5)\n",
    "\n",
    "迭代的终止条件为 maxij{∣∣u(t+1)ij−u(t)ij∣∣}<ε\n",
    "，其中 t 是迭代步数，ε 是一个很小的常数表示误差阈值。也就是说迭代地更新 uij 和 cj 直到前后两次隶属度最大变化值不超过误差阈值。这个过程最终收敛于 Jm\n",
    "\n",
    "的局部极小值点或鞍点。\n",
    "算法步骤\n",
    "\n",
    "可以将模糊c均值聚类的过程归纳为以下几步：\n",
    "\n",
    "    初始化隶属度矩阵 U(0)\n",
    "\n",
    "，若有 N个样本，指定类别数为 C，则隶属度矩阵应当是 N∗C\n",
    "的矩阵；\n",
    "根据式(5)更新聚类中心 cj,j=1,...,C\n",
    "；\n",
    "根据式(4)更新 U(t),U(t+1)\n",
    "；\n",
    "若满足终止条件 maxij{∣∣u(t+1)ij−u(t)ij∣∣}<ε\n",
    "\n",
    "    则停止迭代，否则返回步骤2。\n",
    "\n",
    "程序实现\n",
    "\n",
    "下面代码以Iris数据集为例实现了fuzzy c-means。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a46c5-4002-445a-abfd-f693c012398b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'zip' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e70459c08f63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuzzyCMeansClustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e70459c08f63>\u001b[0m in \u001b[0;36mfuzzyCMeansClustering\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mcurr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcurr\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mMAX_ITER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mcluster_centers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculateClusterCenter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmembership_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mmembership_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdateMembershipValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmembership_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_centers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mcluster_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetClusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmembership_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e70459c08f63>\u001b[0m in \u001b[0;36mcalculateClusterCenter\u001b[0;34m(membership_mat)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mcluster_centers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_mem_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mxraised\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mdenominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxraised\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'zip' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "'''\n",
    "@Date    : 2019/9/11\n",
    "@Author  : Rezero\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def loadData(datapath):\n",
    "    data = pd.read_csv(datapath, sep=',', header=None)\n",
    "    data = data.sample(frac=1.0)   # 打乱数据顺序\n",
    "    dataX = data.iloc[:, :-1].values # 特征\n",
    "    labels = data.iloc[:, -1].values # 标签\n",
    "    # 将标签类别用 0, 1, 2表示\n",
    "    labels[np.where(labels == \"Iris-setosa\")] = 0\n",
    "    labels[np.where(labels == \"Iris-versicolor\")] = 1\n",
    "    labels[np.where(labels == \"Iris-virginica\")] = 2\n",
    "\n",
    "    return dataX, labels\n",
    "\n",
    "\n",
    "def initialize_U(samples, classes):\n",
    "    U = np.random.rand(samples, classes)  # 先生成随机矩阵\n",
    "    sumU = 1 / np.sum(U, axis=1)   # 求每行的和\n",
    "    U = np.multiply(U.T, sumU)   # 使隶属度矩阵每一行和为1\n",
    "\n",
    "    return U.T\n",
    "\n",
    "# 计算样本和簇中心的距离，这里使用欧氏距离\n",
    "def distance(X, centroid):\n",
    "    return np.sqrt(np.sum((X-centroid)**2, axis=1))\n",
    "\n",
    "\n",
    "def computeU(X, centroids, m=2):\n",
    "    sampleNumber = X.shape[0]  # 样本数\n",
    "    classes = len(centroids)\n",
    "    U = np.zeros((sampleNumber, classes))\n",
    "    # 更新隶属度矩阵\n",
    "    for i in range(classes):\n",
    "        for k in range(classes):\n",
    "            U[:, i] += (distance(X, centroids[i]) / distance(X, centroids[k])) ** (2 / (m - 1))\n",
    "    U = 1 / U\n",
    "\n",
    "    return U\n",
    "\n",
    "\n",
    "def ajustCentroid(centroids, U, labels):\n",
    "    newCentroids = [[], [], []]\n",
    "    curr = np.argmax(U, axis=1)  # 当前中心顺序得到的标签\n",
    "    for i in range(len(centroids)):\n",
    "        index = np.where(curr == i)   # 建立中心和类别的映射\n",
    "        trueLabel = list(labels[index])  # 获取labels[index]出现次数最多的元素，就是真实类别\n",
    "        trueLabel = max(set(trueLabel), key=trueLabel.count)\n",
    "        newCentroids[trueLabel] = centroids[i]\n",
    "    return newCentroids\n",
    "\n",
    "def cluster(data, labels, m, classes, EPS):\n",
    "    \"\"\"\n",
    "    :param data: 数据集\n",
    "    :param m: 模糊系数(fuzziness coefficient)\n",
    "    :param classes: 类别数\n",
    "    :return: 聚类中心\n",
    "    \"\"\"\n",
    "    sampleNumber = data.shape[0]  # 样本数\n",
    "    cNumber = data.shape[1]       # 特征数\n",
    "    U = initialize_U(sampleNumber, classes)   # 初始化隶属度矩阵\n",
    "    U_old = np.zeros((sampleNumber, classes))\n",
    "\n",
    "    while True:\n",
    "        centroids = []\n",
    "        # 更新簇中心\n",
    "        for i in range(classes):\n",
    "            centroid = np.dot(U[:, i]**m, data) / (np.sum(U[:, i]**m))\n",
    "            centroids.append(centroid)\n",
    "\n",
    "        U_old = U.copy()\n",
    "        U = computeU(data, centroids, m)  # 计算新的隶属度矩阵\n",
    "\n",
    "        if np.max(np.abs(U - U_old)) < EPS:\n",
    "            # 这里的类别和数据标签并不是一一对应的, 调整使得第i个中心表示第i类\n",
    "            centroids = ajustCentroid(centroids, U, labels)\n",
    "            return centroids, U\n",
    "\n",
    "\n",
    "# 预测所属的类别\n",
    "def predict(X, centroids):\n",
    "    labels = np.zeros(X.shape[0])\n",
    "    U = computeU(X, centroids)  # 计算隶属度矩阵\n",
    "    labels = np.argmax(U, axis=1)  # 找到隶属度矩阵中每行的最大值，即该样本最大可能所属类别\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def main():\n",
    "    datapath = \"iris.data\"\n",
    "    dataX, labels = loadData(datapath)  # 读取数据\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    ratio = 0.6  # 训练集的比例\n",
    "    trainLength = int(dataX.shape[0] * ratio)  # 训练集长度\n",
    "    trainX = dataX[:trainLength, :]\n",
    "    trainLabels = labels[:trainLength]\n",
    "    testX = dataX[trainLength:, :]\n",
    "    testLabels = labels[trainLength:]\n",
    "\n",
    "    EPS = 1e-6   # 停止误差条件\n",
    "    m = 2        # 模糊因子\n",
    "    classes = 3  # 类别数\n",
    "    # 得到各类别的中心\n",
    "    centroids, U = cluster(trainX, trainLabels, m, classes, EPS)\n",
    "\n",
    "    trainLabels_prediction = predict(trainX, centroids)\n",
    "    testLabels_prediction = predict(testX, centroids)\n",
    "\n",
    "\n",
    "    train_error = 1 - np.sum(np.abs(trainLabels_prediction - trainLabels)) / trainLength\n",
    "    test_error = 1 - np.sum(np.abs(testLabels_prediction - testLabels)) / (dataX.shape[0] - trainLength)\n",
    "    print(\"Clustering on traintset is %.2f%%\" % (train_error*100))\n",
    "    print(\"Clustering on testset is %.2f%%\" % (test_error*100))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
